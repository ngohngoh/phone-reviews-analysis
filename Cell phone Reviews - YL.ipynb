{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Phone Reviews Analysis - Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:28:07.952975Z",
     "start_time": "2020-03-19T07:28:07.947989Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eugene\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import nltk \n",
    "import re\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Note: You will need to install the packages below to use them\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:28:17.855560Z",
     "start_time": "2020-03-19T07:28:08.448855Z"
    }
   },
   "outputs": [],
   "source": [
    "#Just write your directory here\n",
    "#data_dir = 'C:/Users/owzhe/Downloads/14-million-cell-phone-reviews/'\n",
    "data_dir = 'C:/Users/Eugene/Desktop/Modules/Text Mining and Language Processing (IS450)/Project/Potential datasets/14-million-cell-phone-reviews/'\n",
    "reviews_files = os.listdir(data_dir)\n",
    "\n",
    "reviews_df = pd.DataFrame()\n",
    "\n",
    "for file in reviews_files:\n",
    "    current = pd.read_csv(data_dir + file, encoding = \"ISO-8859-1\")\n",
    "    reviews_df = reviews_df.append(current)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:28:17.976237Z",
     "start_time": "2020-03-19T07:28:17.857554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1415133\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>score</th>\n",
       "      <th>score_max</th>\n",
       "      <th>extract</th>\n",
       "      <th>author</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>verizonwireless.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>As a diehard Samsung fan who has had every Sam...</td>\n",
       "      <td>CarolAnn35</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>phonearena.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>james0923</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Adequate feel. Nice heft. Processor's still sl...</td>\n",
       "      <td>R. Craig</td>\n",
       "      <td>Samsung Galaxy S8 (64GB) G950U 5.8\" 4G LTE Unl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>samsung.com</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never disappointed. One of the reasons I've be...</td>\n",
       "      <td>Buster2020</td>\n",
       "      <td>Samsung Galaxy S8 64GB (AT&amp;T)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>verizonwireless.com</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I've now found that i'm in a group of people t...</td>\n",
       "      <td>S Ate Mine</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone_url       date lang country            source  \\\n",
       "0  /cellphones/samsung-galaxy-s8/   5/2/2017   en      us  Verizon Wireless   \n",
       "1  /cellphones/samsung-galaxy-s8/  4/28/2017   en      us       Phone Arena   \n",
       "2  /cellphones/samsung-galaxy-s8/   5/4/2017   en      us            Amazon   \n",
       "3  /cellphones/samsung-galaxy-s8/   5/2/2017   en      us           Samsung   \n",
       "4  /cellphones/samsung-galaxy-s8/  5/11/2017   en      us  Verizon Wireless   \n",
       "\n",
       "                domain  score  score_max  \\\n",
       "0  verizonwireless.com   10.0       10.0   \n",
       "1       phonearena.com   10.0       10.0   \n",
       "2           amazon.com    6.0       10.0   \n",
       "3          samsung.com    9.2       10.0   \n",
       "4  verizonwireless.com    4.0       10.0   \n",
       "\n",
       "                                             extract       author  \\\n",
       "0  As a diehard Samsung fan who has had every Sam...   CarolAnn35   \n",
       "1  Love the phone. the phone is sleek and smooth ...    james0923   \n",
       "2  Adequate feel. Nice heft. Processor's still sl...     R. Craig   \n",
       "3  Never disappointed. One of the reasons I've be...  Buster2020    \n",
       "4  I've now found that i'm in a group of people t...   S Ate Mine   \n",
       "\n",
       "                                             product  \n",
       "0                                  Samsung Galaxy S8  \n",
       "1                                  Samsung Galaxy S8  \n",
       "2  Samsung Galaxy S8 (64GB) G950U 5.8\" 4G LTE Unl...  \n",
       "3                      Samsung Galaxy S8 64GB (AT&T)  \n",
       "4                                  Samsung Galaxy S8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(reviews_df))\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:28:20.362312Z",
     "start_time": "2020-03-19T07:28:19.922375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554746\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>score</th>\n",
       "      <th>score_max</th>\n",
       "      <th>extract</th>\n",
       "      <th>author</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>verizonwireless.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>As a diehard Samsung fan who has had every Sam...</td>\n",
       "      <td>CarolAnn35</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>phonearena.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>james0923</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Adequate feel. Nice heft. Processor's still sl...</td>\n",
       "      <td>R. Craig</td>\n",
       "      <td>Samsung Galaxy S8 (64GB) G950U 5.8\" 4G LTE Unl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>samsung.com</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never disappointed. One of the reasons I've be...</td>\n",
       "      <td>Buster2020</td>\n",
       "      <td>Samsung Galaxy S8 64GB (AT&amp;T)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>verizonwireless.com</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I've now found that i'm in a group of people t...</td>\n",
       "      <td>S Ate Mine</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone_url       date lang country            source  \\\n",
       "0  /cellphones/samsung-galaxy-s8/   5/2/2017   en      us  Verizon Wireless   \n",
       "1  /cellphones/samsung-galaxy-s8/  4/28/2017   en      us       Phone Arena   \n",
       "2  /cellphones/samsung-galaxy-s8/   5/4/2017   en      us            Amazon   \n",
       "3  /cellphones/samsung-galaxy-s8/   5/2/2017   en      us           Samsung   \n",
       "4  /cellphones/samsung-galaxy-s8/  5/11/2017   en      us  Verizon Wireless   \n",
       "\n",
       "                domain  score  score_max  \\\n",
       "0  verizonwireless.com   10.0       10.0   \n",
       "1       phonearena.com   10.0       10.0   \n",
       "2           amazon.com    6.0       10.0   \n",
       "3          samsung.com    9.2       10.0   \n",
       "4  verizonwireless.com    4.0       10.0   \n",
       "\n",
       "                                             extract       author  \\\n",
       "0  As a diehard Samsung fan who has had every Sam...   CarolAnn35   \n",
       "1  Love the phone. the phone is sleek and smooth ...    james0923   \n",
       "2  Adequate feel. Nice heft. Processor's still sl...     R. Craig   \n",
       "3  Never disappointed. One of the reasons I've be...  Buster2020    \n",
       "4  I've now found that i'm in a group of people t...   S Ate Mine   \n",
       "\n",
       "                                             product  \n",
       "0                                  Samsung Galaxy S8  \n",
       "1                                  Samsung Galaxy S8  \n",
       "2  Samsung Galaxy S8 (64GB) G950U 5.8\" 4G LTE Unl...  \n",
       "3                      Samsung Galaxy S8 64GB (AT&T)  \n",
       "4                                  Samsung Galaxy S8  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking only the reviews that are in english\n",
    "reviews_en_df = reviews_df[reviews_df['lang'] == 'en']\n",
    "print(len(reviews_en_df))\n",
    "reviews_en_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:28:21.829608Z",
     "start_time": "2020-03-19T07:28:21.710960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4533\n",
      "['/cellphones/samsung-galaxy-s8/'\n",
      " '/cellphones/samsung-galaxy-s6-edgeplus/'\n",
      " '/cellphones/samsung-galaxy-s8-plus/' ... '/cellphones/ericsson-pf-768/'\n",
      " '/cellphones/motorola-m3288/' '/cellphones/maxon-mx-3204/']\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_en_df['phone_url'].unique()))\n",
    "print(reviews_en_df['phone_url'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:28:23.999567Z",
     "start_time": "2020-03-19T07:28:23.995541Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the function to return the phone model from the URL\n",
    "def phone_model(url):\n",
    "    phone_type = ' '.join(url[12:-1].split('-')).title()\n",
    "    return phone_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:28:25.111269Z",
     "start_time": "2020-03-19T07:28:24.263184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eugene\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Applying the phone_model function on the url \n",
    "reviews_en_df['phone_model'] = reviews_en_df['phone_url'].apply(phone_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:28:26.379619Z",
     "start_time": "2020-03-19T07:28:26.332807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4533\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_en_df['phone_model'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:28:28.009884Z",
     "start_time": "2020-03-19T07:28:27.843799Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating another copy of the reviews_df\n",
    "reviews_copy_df = reviews_en_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:28:28.462405Z",
     "start_time": "2020-03-19T07:28:28.458386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Found out that the dates are abit off - majority are in month/day/year but there is around 20k that is day/month/year\n",
    "def check_date(row_date):\n",
    "    month, day, year = row_date.split('/')\n",
    "    isValid = True\n",
    "    try:\n",
    "        datetime.datetime(int(year), int(month), int(day))\n",
    "    except:\n",
    "        isValid = False\n",
    "    \n",
    "    return isValid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:28:29.534587Z",
     "start_time": "2020-03-19T07:28:29.530596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a year column\n",
    "def review_year(row_date):\n",
    "    month, day, year = row_date.split('/')\n",
    "\n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:31:13.968752Z",
     "start_time": "2020-03-19T07:31:13.067735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>score</th>\n",
       "      <th>score_max</th>\n",
       "      <th>extract</th>\n",
       "      <th>author</th>\n",
       "      <th>product</th>\n",
       "      <th>phone_model</th>\n",
       "      <th>date_check</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>verizonwireless.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>As a diehard Samsung fan who has had every Sam...</td>\n",
       "      <td>CarolAnn35</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>True</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>phonearena.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>james0923</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>True</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Adequate feel. Nice heft. Processor's still sl...</td>\n",
       "      <td>R. Craig</td>\n",
       "      <td>Samsung Galaxy S8 (64GB) G950U 5.8\" 4G LTE Unl...</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>True</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>samsung.com</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never disappointed. One of the reasons I've be...</td>\n",
       "      <td>Buster2020</td>\n",
       "      <td>Samsung Galaxy S8 64GB (AT&amp;T)</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>True</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-galaxy-s8/</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>verizonwireless.com</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I've now found that i'm in a group of people t...</td>\n",
       "      <td>S Ate Mine</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>True</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone_url       date lang country            source  \\\n",
       "0  /cellphones/samsung-galaxy-s8/   5/2/2017   en      us  Verizon Wireless   \n",
       "1  /cellphones/samsung-galaxy-s8/  4/28/2017   en      us       Phone Arena   \n",
       "2  /cellphones/samsung-galaxy-s8/   5/4/2017   en      us            Amazon   \n",
       "3  /cellphones/samsung-galaxy-s8/   5/2/2017   en      us           Samsung   \n",
       "4  /cellphones/samsung-galaxy-s8/  5/11/2017   en      us  Verizon Wireless   \n",
       "\n",
       "                domain  score  score_max  \\\n",
       "0  verizonwireless.com   10.0       10.0   \n",
       "1       phonearena.com   10.0       10.0   \n",
       "2           amazon.com    6.0       10.0   \n",
       "3          samsung.com    9.2       10.0   \n",
       "4  verizonwireless.com    4.0       10.0   \n",
       "\n",
       "                                             extract       author  \\\n",
       "0  As a diehard Samsung fan who has had every Sam...   CarolAnn35   \n",
       "1  Love the phone. the phone is sleek and smooth ...    james0923   \n",
       "2  Adequate feel. Nice heft. Processor's still sl...     R. Craig   \n",
       "3  Never disappointed. One of the reasons I've be...  Buster2020    \n",
       "4  I've now found that i'm in a group of people t...   S Ate Mine   \n",
       "\n",
       "                                             product        phone_model  \\\n",
       "0                                  Samsung Galaxy S8  Samsung Galaxy S8   \n",
       "1                                  Samsung Galaxy S8  Samsung Galaxy S8   \n",
       "2  Samsung Galaxy S8 (64GB) G950U 5.8\" 4G LTE Unl...  Samsung Galaxy S8   \n",
       "3                      Samsung Galaxy S8 64GB (AT&T)  Samsung Galaxy S8   \n",
       "4                                  Samsung Galaxy S8  Samsung Galaxy S8   \n",
       "\n",
       "   date_check  year  \n",
       "0        True  2017  \n",
       "1        True  2017  \n",
       "2        True  2017  \n",
       "3        True  2017  \n",
       "4        True  2017  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_copy_df['date_check'] = reviews_copy_df['date'].apply(check_date)\n",
    "reviews_copy_df['year'] = reviews_copy_df['date'].apply(review_year)\n",
    "reviews_copy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:31:45.210157Z",
     "start_time": "2020-03-19T07:31:45.050434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of wrong dates: 23448\n",
      "No. of correct dates: 531298\n"
     ]
    }
   ],
   "source": [
    "# Checking the number of wrong and correct dates \n",
    "wrong_dates = reviews_copy_df[reviews_copy_df['date_check'] == False]\n",
    "print('No. of wrong dates:', len(wrong_dates))\n",
    "\n",
    "correct_dates = reviews_copy_df[reviews_copy_df['date_check'] == True]\n",
    "print('No. of correct dates:', len(correct_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:31:45.596668Z",
     "start_time": "2020-03-19T07:31:45.590686Z"
    }
   },
   "outputs": [],
   "source": [
    "# Created a function to clean the date for the incorrect date format\n",
    "def clean_date(date):\n",
    "    month, day, year = date.split('/')\n",
    "    return '/'.join([day, month, year])\n",
    "\n",
    "#     for index, row in reviews_df.iterrows():\n",
    "#         month, day, year = row['date'].split('/')\n",
    "#         if row['date_check'] == False:\n",
    "#             reviews_df.loc[index, 'date'] = '/'.join([day, month, year])\n",
    "#             row['date_check'] = True\n",
    "#     return reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:31:46.674979Z",
     "start_time": "2020-03-19T07:31:46.436607Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eugene\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_url</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>score</th>\n",
       "      <th>score_max</th>\n",
       "      <th>extract</th>\n",
       "      <th>author</th>\n",
       "      <th>product</th>\n",
       "      <th>phone_model</th>\n",
       "      <th>date_check</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/cellphones/samsung-s7262-duos-galaxy-ace/</td>\n",
       "      <td>11/17/2015</td>\n",
       "      <td>en</td>\n",
       "      <td>in</td>\n",
       "      <td>Zopper</td>\n",
       "      <td>zopper.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Decent Functions and Easy to Operate Pros:- Th...</td>\n",
       "      <td>Expert Review</td>\n",
       "      <td>Samsung Galaxy Star Pro S7262 Black</td>\n",
       "      <td>Samsung S7262 Duos Galaxy Ace</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cellphones/samsung-s7262-duos-galaxy-ace/</td>\n",
       "      <td>10/29/2015</td>\n",
       "      <td>en</td>\n",
       "      <td>in</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.in</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Not Good Phone such price. Hang too much and v...</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Samsung Galaxy Star Pro GT-S7262 (Midnight Black)</td>\n",
       "      <td>Samsung S7262 Duos Galaxy Ace</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cellphones/samsung-s7262-duos-galaxy-ace/</td>\n",
       "      <td>10/29/2015</td>\n",
       "      <td>en</td>\n",
       "      <td>in</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.in</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>not bad for features</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Samsung Galaxy Star Pro GT-S7262 (Midnight Black)</td>\n",
       "      <td>Samsung S7262 Duos Galaxy Ace</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cellphones/samsung-s7262-duos-galaxy-ace/</td>\n",
       "      <td>10/29/2015</td>\n",
       "      <td>en</td>\n",
       "      <td>in</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.in</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Excellent product</td>\n",
       "      <td>NHK</td>\n",
       "      <td>Samsung Galaxy Star Pro GT-S7262 (Midnight Black)</td>\n",
       "      <td>Samsung S7262 Duos Galaxy Ace</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/cellphones/samsung-s7262-duos-galaxy-ace/</td>\n",
       "      <td>10/27/2015</td>\n",
       "      <td>en</td>\n",
       "      <td>in</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.in</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Good in reasonable price</td>\n",
       "      <td>Rupali</td>\n",
       "      <td>Samsung Galaxy Star Pro GT-S7262 (Midnight Black)</td>\n",
       "      <td>Samsung S7262 Duos Galaxy Ace</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97303</th>\n",
       "      <td>/cellphones/motorola-razr-432872/</td>\n",
       "      <td>5/13/2006</td>\n",
       "      <td>en</td>\n",
       "      <td>gb</td>\n",
       "      <td>Ciao</td>\n",
       "      <td>ciao.co.uk</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I bought this phone originally because I decid...</td>\n",
       "      <td>tblake7</td>\n",
       "      <td>Motorola RAZR</td>\n",
       "      <td>Motorola Razr 432872</td>\n",
       "      <td>False</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97304</th>\n",
       "      <td>/cellphones/motorola-razr-432872/</td>\n",
       "      <td>3/18/2006</td>\n",
       "      <td>en</td>\n",
       "      <td>gb</td>\n",
       "      <td>Ciao</td>\n",
       "      <td>ciao.co.uk</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>After making the switch from an old V60 TDMA, ...</td>\n",
       "      <td>sting_of_the_scorpion</td>\n",
       "      <td>Motorola RAZR</td>\n",
       "      <td>Motorola Razr 432872</td>\n",
       "      <td>False</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97906</th>\n",
       "      <td>/cellphones/alcatel-ot-918d/</td>\n",
       "      <td>1/30/2015</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Excelente producto</td>\n",
       "      <td>norbys moreno</td>\n",
       "      <td>Alcatel One Touch 918S Mix Unlocked GSM Phone ...</td>\n",
       "      <td>Alcatel Ot 918D</td>\n",
       "      <td>False</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97910</th>\n",
       "      <td>/cellphones/alcatel-ot-918d/</td>\n",
       "      <td>11/25/2013</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Older Android version, too many junky apps and...</td>\n",
       "      <td>Amazon Customer \"Jarod\"</td>\n",
       "      <td>Alcatel One Touch 918S Mix Unlocked GSM Phone ...</td>\n",
       "      <td>Alcatel Ot 918D</td>\n",
       "      <td>False</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98243</th>\n",
       "      <td>/cellphones/alcatel-ot-908/</td>\n",
       "      <td>9/21/2011</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>phonearena.com</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Great value phone. Android 2.2.2(Froyo) out of...</td>\n",
       "      <td>Mihai30Rav</td>\n",
       "      <td>Alcatel OT-908</td>\n",
       "      <td>Alcatel Ot 908</td>\n",
       "      <td>False</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23448 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        phone_url        date lang country  \\\n",
       "1      /cellphones/samsung-s7262-duos-galaxy-ace/  11/17/2015   en      in   \n",
       "2      /cellphones/samsung-s7262-duos-galaxy-ace/  10/29/2015   en      in   \n",
       "3      /cellphones/samsung-s7262-duos-galaxy-ace/  10/29/2015   en      in   \n",
       "4      /cellphones/samsung-s7262-duos-galaxy-ace/  10/29/2015   en      in   \n",
       "5      /cellphones/samsung-s7262-duos-galaxy-ace/  10/27/2015   en      in   \n",
       "...                                           ...         ...  ...     ...   \n",
       "97303           /cellphones/motorola-razr-432872/   5/13/2006   en      gb   \n",
       "97304           /cellphones/motorola-razr-432872/   3/18/2006   en      gb   \n",
       "97906                /cellphones/alcatel-ot-918d/   1/30/2015   en      us   \n",
       "97910                /cellphones/alcatel-ot-918d/  11/25/2013   en      us   \n",
       "98243                 /cellphones/alcatel-ot-908/   9/21/2011   en      us   \n",
       "\n",
       "            source          domain  score  score_max  \\\n",
       "1           Zopper      zopper.com   10.0       10.0   \n",
       "2           Amazon       amazon.in    4.0       10.0   \n",
       "3           Amazon       amazon.in    6.0       10.0   \n",
       "4           Amazon       amazon.in   10.0       10.0   \n",
       "5           Amazon       amazon.in    8.0       10.0   \n",
       "...            ...             ...    ...        ...   \n",
       "97303         Ciao      ciao.co.uk    8.0       10.0   \n",
       "97304         Ciao      ciao.co.uk    8.0       10.0   \n",
       "97906       Amazon      amazon.com   10.0       10.0   \n",
       "97910       Amazon      amazon.com    4.0       10.0   \n",
       "98243  Phone Arena  phonearena.com    9.0       10.0   \n",
       "\n",
       "                                                 extract  \\\n",
       "1      Decent Functions and Easy to Operate Pros:- Th...   \n",
       "2      Not Good Phone such price. Hang too much and v...   \n",
       "3                                   not bad for features   \n",
       "4                                      Excellent product   \n",
       "5                               Good in reasonable price   \n",
       "...                                                  ...   \n",
       "97303  I bought this phone originally because I decid...   \n",
       "97304  After making the switch from an old V60 TDMA, ...   \n",
       "97906                                 Excelente producto   \n",
       "97910  Older Android version, too many junky apps and...   \n",
       "98243  Great value phone. Android 2.2.2(Froyo) out of...   \n",
       "\n",
       "                        author  \\\n",
       "1                Expert Review   \n",
       "2              Amazon Customer   \n",
       "3              Amazon Customer   \n",
       "4                          NHK   \n",
       "5                       Rupali   \n",
       "...                        ...   \n",
       "97303                  tblake7   \n",
       "97304    sting_of_the_scorpion   \n",
       "97906            norbys moreno   \n",
       "97910  Amazon Customer \"Jarod\"   \n",
       "98243               Mihai30Rav   \n",
       "\n",
       "                                                 product  \\\n",
       "1                    Samsung Galaxy Star Pro S7262 Black   \n",
       "2      Samsung Galaxy Star Pro GT-S7262 (Midnight Black)   \n",
       "3      Samsung Galaxy Star Pro GT-S7262 (Midnight Black)   \n",
       "4      Samsung Galaxy Star Pro GT-S7262 (Midnight Black)   \n",
       "5      Samsung Galaxy Star Pro GT-S7262 (Midnight Black)   \n",
       "...                                                  ...   \n",
       "97303                                      Motorola RAZR   \n",
       "97304                                      Motorola RAZR   \n",
       "97906  Alcatel One Touch 918S Mix Unlocked GSM Phone ...   \n",
       "97910  Alcatel One Touch 918S Mix Unlocked GSM Phone ...   \n",
       "98243                                     Alcatel OT-908   \n",
       "\n",
       "                         phone_model  date_check  year  \n",
       "1      Samsung S7262 Duos Galaxy Ace       False  2015  \n",
       "2      Samsung S7262 Duos Galaxy Ace       False  2015  \n",
       "3      Samsung S7262 Duos Galaxy Ace       False  2015  \n",
       "4      Samsung S7262 Duos Galaxy Ace       False  2015  \n",
       "5      Samsung S7262 Duos Galaxy Ace       False  2015  \n",
       "...                              ...         ...   ...  \n",
       "97303           Motorola Razr 432872       False  2006  \n",
       "97304           Motorola Razr 432872       False  2006  \n",
       "97906                Alcatel Ot 918D       False  2015  \n",
       "97910                Alcatel Ot 918D       False  2013  \n",
       "98243                 Alcatel Ot 908       False  2011  \n",
       "\n",
       "[23448 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up the date format of the dataframe with wrong dates\n",
    "wrong_dates['date'] = wrong_dates['date'].apply(clean_date)\n",
    "wrong_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:32:37.702990Z",
     "start_time": "2020-03-19T07:32:37.001453Z"
    }
   },
   "outputs": [],
   "source": [
    "# Returning the cleaned dataframe use for analysis \n",
    "cleaned_df = correct_dates.append(wrong_dates, ignore_index=True)\n",
    "cleaned_df = cleaned_df[cleaned_df['year'].astype(int) >= 2013]\n",
    "cleaned_df.drop(columns=['phone_url', 'date_check', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:32:38.008580Z",
     "start_time": "2020-03-19T07:32:37.704949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score         158\n",
       "score_max     158\n",
       "extract      3448\n",
       "author        305\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking null rows\n",
    "null_columns = cleaned_df.columns[cleaned_df.isna().any()]\n",
    "cleaned_df[null_columns].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T07:32:38.140740Z",
     "start_time": "2020-03-19T07:32:38.010574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400063"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.dropna(subset=['extract'], inplace=True)\n",
    "len(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing pre-2007 reviews\n",
    "# date_list = cleaned_df.loc[:,'date'].tolist()\n",
    "# year_list = []\n",
    "# for dates in date_list:\n",
    "#     year = dates[-4:]\n",
    "#     if (int(year)>=2007):\n",
    "#         year_list.append(year)\n",
    "#     else:\n",
    "#         year_list.append(\"drop\")\n",
    "# cleaned_df.insert(0, 'year', year_list)\n",
    "# cleaned_df.drop( cleaned_df[ cleaned_df['year'] == \"drop\" ].index , inplace=True)\n",
    "# cleaned_df.drop(['year'], axis=1, inplace = True)\n",
    "# len(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing/Opening pickle file for the cleaned dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T10:18:30.305525Z",
     "start_time": "2020-03-28T10:18:28.611909Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE CLEANED DATAFRAME FROM ABOVE @@@@@@@@@###\n",
    "#pickle.dump(cleaned_df, open(\"cleaned_reviews_df.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE CLEANED DATAFRAME FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "#cleaned_df = pickle.load(open(\"cleaned_reviews_df.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T10:18:31.405741Z",
     "start_time": "2020-03-28T10:18:31.369787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>score</th>\n",
       "      <th>score_max</th>\n",
       "      <th>extract</th>\n",
       "      <th>author</th>\n",
       "      <th>product</th>\n",
       "      <th>phone_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>verizonwireless.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>As a diehard Samsung fan who has had every Sam...</td>\n",
       "      <td>CarolAnn35</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>phonearena.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>james0923</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Adequate feel. Nice heft. Processor's still sl...</td>\n",
       "      <td>R. Craig</td>\n",
       "      <td>Samsung Galaxy S8 (64GB) G950U 5.8\" 4G LTE Unl...</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>samsung.com</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never disappointed. One of the reasons I've be...</td>\n",
       "      <td>Buster2020</td>\n",
       "      <td>Samsung Galaxy S8 64GB (AT&amp;T)</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>verizonwireless.com</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I've now found that i'm in a group of people t...</td>\n",
       "      <td>S Ate Mine</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date lang country            source               domain  score  \\\n",
       "0   5/2/2017   en      us  Verizon Wireless  verizonwireless.com   10.0   \n",
       "1  4/28/2017   en      us       Phone Arena       phonearena.com   10.0   \n",
       "2   5/4/2017   en      us            Amazon           amazon.com    6.0   \n",
       "3   5/2/2017   en      us           Samsung          samsung.com    9.2   \n",
       "4  5/11/2017   en      us  Verizon Wireless  verizonwireless.com    4.0   \n",
       "\n",
       "   score_max                                            extract       author  \\\n",
       "0       10.0  As a diehard Samsung fan who has had every Sam...   CarolAnn35   \n",
       "1       10.0  Love the phone. the phone is sleek and smooth ...    james0923   \n",
       "2       10.0  Adequate feel. Nice heft. Processor's still sl...     R. Craig   \n",
       "3       10.0  Never disappointed. One of the reasons I've be...  Buster2020    \n",
       "4       10.0  I've now found that i'm in a group of people t...   S Ate Mine   \n",
       "\n",
       "                                             product        phone_model  \n",
       "0                                  Samsung Galaxy S8  Samsung Galaxy S8  \n",
       "1                                  Samsung Galaxy S8  Samsung Galaxy S8  \n",
       "2  Samsung Galaxy S8 (64GB) G950U 5.8\" 4G LTE Unl...  Samsung Galaxy S8  \n",
       "3                      Samsung Galaxy S8 64GB (AT&T)  Samsung Galaxy S8  \n",
       "4                                  Samsung Galaxy S8  Samsung Galaxy S8  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T10:18:34.750967Z",
     "start_time": "2020-03-28T10:18:34.729025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>score</th>\n",
       "      <th>score_max</th>\n",
       "      <th>extract</th>\n",
       "      <th>author</th>\n",
       "      <th>product</th>\n",
       "      <th>phone_model</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>verizonwireless.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>As a diehard Samsung fan who has had every Sam...</td>\n",
       "      <td>CarolAnn35</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/28/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Phone Arena</td>\n",
       "      <td>phonearena.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Love the phone. the phone is sleek and smooth ...</td>\n",
       "      <td>james0923</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/4/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Adequate feel. Nice heft. Processor's still sl...</td>\n",
       "      <td>R. Craig</td>\n",
       "      <td>Samsung Galaxy S8 (64GB) G950U 5.8\" 4G LTE Unl...</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>samsung.com</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Never disappointed. One of the reasons I've be...</td>\n",
       "      <td>Buster2020</td>\n",
       "      <td>Samsung Galaxy S8 64GB (AT&amp;T)</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Verizon Wireless</td>\n",
       "      <td>verizonwireless.com</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I've now found that i'm in a group of people t...</td>\n",
       "      <td>S Ate Mine</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>Samsung Galaxy S8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554608</th>\n",
       "      <td>3/18/2014</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I love this phone! The only problem I have is ...</td>\n",
       "      <td>Brandi \"Brandi\"</td>\n",
       "      <td>Motorola Droid RAZR 4G LTE Android Smartphone ...</td>\n",
       "      <td>Motorola Razr 432872</td>\n",
       "      <td>400058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554609</th>\n",
       "      <td>1/21/2014</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I love the 4G internet. I like all of the appl...</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Motorola Droid RAZR 4G LTE Android Smartphone ...</td>\n",
       "      <td>Motorola Razr 432872</td>\n",
       "      <td>400059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554610</th>\n",
       "      <td>8/30/2013</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>This phone works great. Is in good condition. ...</td>\n",
       "      <td>roshanda</td>\n",
       "      <td>Motorola Droid RAZR 4G LTE Android Smartphone ...</td>\n",
       "      <td>Motorola Razr 432872</td>\n",
       "      <td>400060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554743</th>\n",
       "      <td>1/30/2015</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Excelente producto</td>\n",
       "      <td>norbys moreno</td>\n",
       "      <td>Alcatel One Touch 918S Mix Unlocked GSM Phone ...</td>\n",
       "      <td>Alcatel Ot 918D</td>\n",
       "      <td>400061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554744</th>\n",
       "      <td>11/25/2013</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Older Android version, too many junky apps and...</td>\n",
       "      <td>Amazon Customer \"Jarod\"</td>\n",
       "      <td>Alcatel One Touch 918S Mix Unlocked GSM Phone ...</td>\n",
       "      <td>Alcatel Ot 918D</td>\n",
       "      <td>400062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400063 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date lang country            source               domain  score  \\\n",
       "0         5/2/2017   en      us  Verizon Wireless  verizonwireless.com   10.0   \n",
       "1        4/28/2017   en      us       Phone Arena       phonearena.com   10.0   \n",
       "2         5/4/2017   en      us            Amazon           amazon.com    6.0   \n",
       "3         5/2/2017   en      us           Samsung          samsung.com    9.2   \n",
       "4        5/11/2017   en      us  Verizon Wireless  verizonwireless.com    4.0   \n",
       "...            ...  ...     ...               ...                  ...    ...   \n",
       "554608   3/18/2014   en      us            Amazon           amazon.com    8.0   \n",
       "554609   1/21/2014   en      us            Amazon           amazon.com   10.0   \n",
       "554610   8/30/2013   en      us            Amazon           amazon.com   10.0   \n",
       "554743   1/30/2015   en      us            Amazon           amazon.com   10.0   \n",
       "554744  11/25/2013   en      us            Amazon           amazon.com    4.0   \n",
       "\n",
       "        score_max                                            extract  \\\n",
       "0            10.0  As a diehard Samsung fan who has had every Sam...   \n",
       "1            10.0  Love the phone. the phone is sleek and smooth ...   \n",
       "2            10.0  Adequate feel. Nice heft. Processor's still sl...   \n",
       "3            10.0  Never disappointed. One of the reasons I've be...   \n",
       "4            10.0  I've now found that i'm in a group of people t...   \n",
       "...           ...                                                ...   \n",
       "554608       10.0  I love this phone! The only problem I have is ...   \n",
       "554609       10.0  I love the 4G internet. I like all of the appl...   \n",
       "554610       10.0  This phone works great. Is in good condition. ...   \n",
       "554743       10.0                                 Excelente producto   \n",
       "554744       10.0  Older Android version, too many junky apps and...   \n",
       "\n",
       "                         author  \\\n",
       "0                    CarolAnn35   \n",
       "1                     james0923   \n",
       "2                      R. Craig   \n",
       "3                   Buster2020    \n",
       "4                    S Ate Mine   \n",
       "...                         ...   \n",
       "554608          Brandi \"Brandi\"   \n",
       "554609          Amazon Customer   \n",
       "554610                 roshanda   \n",
       "554743            norbys moreno   \n",
       "554744  Amazon Customer \"Jarod\"   \n",
       "\n",
       "                                                  product  \\\n",
       "0                                       Samsung Galaxy S8   \n",
       "1                                       Samsung Galaxy S8   \n",
       "2       Samsung Galaxy S8 (64GB) G950U 5.8\" 4G LTE Unl...   \n",
       "3                           Samsung Galaxy S8 64GB (AT&T)   \n",
       "4                                       Samsung Galaxy S8   \n",
       "...                                                   ...   \n",
       "554608  Motorola Droid RAZR 4G LTE Android Smartphone ...   \n",
       "554609  Motorola Droid RAZR 4G LTE Android Smartphone ...   \n",
       "554610  Motorola Droid RAZR 4G LTE Android Smartphone ...   \n",
       "554743  Alcatel One Touch 918S Mix Unlocked GSM Phone ...   \n",
       "554744  Alcatel One Touch 918S Mix Unlocked GSM Phone ...   \n",
       "\n",
       "                 phone_model   index  \n",
       "0          Samsung Galaxy S8       0  \n",
       "1          Samsung Galaxy S8       1  \n",
       "2          Samsung Galaxy S8       2  \n",
       "3          Samsung Galaxy S8       3  \n",
       "4          Samsung Galaxy S8       4  \n",
       "...                      ...     ...  \n",
       "554608  Motorola Razr 432872  400058  \n",
       "554609  Motorola Razr 432872  400059  \n",
       "554610  Motorola Razr 432872  400060  \n",
       "554743       Alcatel Ot 918D  400061  \n",
       "554744       Alcatel Ot 918D  400062  \n",
       "\n",
       "[400063 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create an index series to find back the actual extract later on\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_len = len(cleaned_df)\n",
    "index_series = np.arange(data_len)\n",
    "\n",
    "cleaned_df['index'] = index_series\n",
    "\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T10:18:36.252062Z",
     "start_time": "2020-03-28T10:18:35.413855Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence_list = []\n",
    "index_list = []\n",
    "scores = cleaned_df['score'].tolist()\n",
    "index_score_list = []\n",
    "\n",
    "extract_list = list(cleaned_df['extract'])\n",
    "\n",
    "for num in index_series:\n",
    "    sentences = extract_list[num]\n",
    "    sentence_break = re.split(r'[.?!]', sentences)\n",
    "    for sentence in sentence_break:\n",
    "        if len(sentence) > 0:\n",
    "            sentence_list.append(sentence.strip())\n",
    "            index_list.append(num)\n",
    "            index_score_list.append(scores[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T10:18:36.894427Z",
     "start_time": "2020-03-28T10:18:36.253639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025939, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df = pd.DataFrame()\n",
    "sentences_df['sentence'] = sentence_list\n",
    "sentences_df['index'] = index_list\n",
    "\n",
    "sentences_df.dropna(inplace=True)\n",
    "\n",
    "sentences_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  #1 LDA Gensim Model - All Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T16:26:09.009015Z",
     "start_time": "2020-03-21T16:26:09.003070Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "import re\n",
    "\n",
    "def clean_sentence(sentence_list):\n",
    "    stop_list = nltk.corpus.stopwords.words('english')\n",
    "    tokenizer = nltk.tokenize.word_tokenize\n",
    "\n",
    "    sentence_list  = [tokenizer(sentence.lower()) for sentence in sentence_list]\n",
    "    sentence_list = [[w for w in sentence if re.search('^[a-z]+$',w)] for sentence in sentence_list]\n",
    "    sentence_list = [[w for w in sentence if w not in stop_list] for sentence in sentence_list]\n",
    "\n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T16:29:01.965649Z",
     "start_time": "2020-03-21T16:26:10.151405Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence_list = sentences_df['sentence'].values.tolist()\n",
    "sentences_df['bag of words'] = clean_sentence(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T16:31:28.704385Z",
     "start_time": "2020-03-21T16:31:28.682444Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences_words = sentences_df['bag of words'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T16:31:52.751503Z",
     "start_time": "2020-03-21T16:31:29.805451Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Using gensim to create a dictionary object of all the words in all extracts\n",
    "sentence_dict = gensim.corpora.Dictionary(sentences_words)\n",
    "\n",
    "# Returning the word vector for each extract from the gensim dict of words\n",
    "sentence_vecs = [sentence_dict.doc2bow(words) for words in sentences_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T17:33:46.568052Z",
     "start_time": "2020-03-21T16:36:34.524176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the optimal number of topics\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "iterations = 100\n",
    "passes = 1\n",
    "gensim_all_texts_list = []\n",
    "\n",
    "for num_topic in range(3, 10):\n",
    "    model_val = []\n",
    "    gensim_all_texts = gensim.models.ldamodel.LdaModel(corpus=sentence_vecs, id2word=sentence_dict, num_topics=num_topic, iterations = iterations, passes = passes)\n",
    "    coh_model = CoherenceModel(model=gensim_all_texts, texts=sentences_words, dictionary=sentence_dict, coherence='c_v')\n",
    "    model_val.append(gensim_all_texts)\n",
    "    model_val.append(coh_model.get_coherence())\n",
    "    model_val.append(num_topic)\n",
    "    gensim_all_texts_list.append(model_val)\n",
    "    print(\"Topic \" + str(num_topic) + \" Score: \" + str(coh_model.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T17:55:51.753770Z",
     "start_time": "2020-03-21T17:55:51.385962Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "coh_val = [coh for model, coh, topic in gensim_all_texts_list]\n",
    "\n",
    "x = range(3, 10)\n",
    "plt.plot(x, coh_val)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T17:55:51.803665Z",
     "start_time": "2020-03-21T17:55:51.755764Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gensim LDA Model - topics\n",
    "\n",
    "for model in gensim_all_texts_list:\n",
    "    print(\"Model #{} Coherence Score: {}\".format(model[2], model[1]))\n",
    "    topics = model.show_topics(formatted=False)\n",
    "    for topic, word_list in topics:\n",
    "        topic_num = topic + 1\n",
    "        result_list = []\n",
    "        for word, word_prob in word_list:\n",
    "            result_list.append(word)\n",
    "        print(\"Topic {}: {}\".format(topic_num, ', '.join(result_list)))\n",
    "    print('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T17:55:57.685546Z",
     "start_time": "2020-03-21T17:55:57.596784Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE GENSIM MODELS FROM ABOVE @@@@@@@@@###\n",
    "#pickle.dump(gensim_all_texts_list, open(\"gensim_all_texts.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE GENSIM MODELS FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "# gensim_all_texts_list = pickle.load(open(\"gensim_all_texts.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #1 LDA Mallet Model - All Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T19:10:50.168223Z",
     "start_time": "2020-03-21T17:56:03.362890Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os \n",
    "\n",
    "os.environ.update({'MALLET_HOME':r'D:\\\\Softwares\\\\mallet-2.0.8'})\n",
    "mallet_path = r'D:\\\\Softwares\\\\mallet-2.0.8\\\\bin\\\\mallet'\n",
    "\n",
    "mallet_all_texts_list = []\n",
    "\n",
    "for num_topic in range(3, 10):\n",
    "    model_val = []\n",
    "    mallet_all_texts = gensim.models.wrappers.LdaMallet(mallet_path, corpus=sentence_vecs, id2word=sentence_dict, num_topics=num_topic)\n",
    "    mallet_coh_model = CoherenceModel(model=mallet_all_texts, texts=sentences_words, dictionary=sentence_dict, coherence='c_v')\n",
    "    model_val.append(mallet_all_texts)\n",
    "    model_val.append(mallet_coh_model.get_coherence())\n",
    "    model_val.append(num_topic)\n",
    "    mallet_all_texts_list.append(model_val)\n",
    "    print(\"Topic \" + str(num_topic) + \" Score: \" + str(mallet_coh_model.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T19:20:55.769530Z",
     "start_time": "2020-03-21T19:20:55.564502Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mallet_coh_val = [coh for model, coh, topic in mallet_all_texts_list]\n",
    "\n",
    "x = range(3, 10)\n",
    "plt.plot(x, mallet_coh_val)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T19:20:57.289028Z",
     "start_time": "2020-03-21T19:20:57.240160Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mallet LDA Model - topics\n",
    "\n",
    "for model in mallet_all_texts_list:\n",
    "    print(\"Model #{} Coherence Score: {}\".format(model[2], model[1]))\n",
    "    topics = model.show_topics(formatted=False)\n",
    "    for topic, word_list in topics:\n",
    "        topic_num = topic + 1\n",
    "        result_list = []\n",
    "        for word, word_prob in word_list:\n",
    "            result_list.append(word)\n",
    "        print(\"Topic {}: {}\".format(topic_num, ', '.join(result_list)))\n",
    "    print('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:14:07.295846Z",
     "start_time": "2020-03-22T08:14:06.657541Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE MODELS FROM ABOVE @@@@@@@@@###\n",
    "pickle.dump(mallet_all_texts_list, open(\"mallet_all_texts.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE MODELS FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "# mallet_all_texts_list = pickle.load(open(\"mallet_all_texts.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #2 LDA Gensim Model - Nouns Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:18:58.355703Z",
     "start_time": "2020-03-22T08:18:57.802182Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences_df = pd.DataFrame()\n",
    "sentences_df['sentence'] = sentence_list\n",
    "sentences_df['index'] = index_list\n",
    "sentences_df.dropna(inplace=True)\n",
    "\n",
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T17:21:13.724275Z",
     "start_time": "2020-03-22T17:21:13.685379Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stop_list = nltk.corpus.stopwords.words('english')\n",
    "tokenizer = nltk.tokenize.word_tokenize\n",
    "extra_stop_words = ['phone', 'iphone', 'nokia', 'samsung', 'htc', 'lg', 'galaxy', 'ca', 'motorola', 'android', 'verizon', 'i', '%', 't', 's']\n",
    "\n",
    "def get_nouns(sentence_row):\n",
    "\n",
    "    noun_list = []\n",
    "    sentence = nltk.pos_tag(tokenizer(sentence_row.lower()))\n",
    "    for w, pos in sentence: \n",
    "        if pos == 'NN' and w not in extra_stop_words:\n",
    "            noun_list.append(w)\n",
    "    \n",
    "    return noun_list\n",
    "\n",
    "#     sentence_list = [tokenizer(sentence.lower()) for sentence in sentence_list]\n",
    "#     sentence_tagging = [nltk.pos_tag(sentence) for sentence in sentence_list] \n",
    "#     sentence_nouns = [w for w in sentence if is_noun(w) for sentence in sentence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T18:11:51.222279Z",
     "start_time": "2020-03-22T17:21:21.072870Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences_df['sentence_tags'] = sentences_df['sentence'].apply(get_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T18:23:58.833917Z",
     "start_time": "2020-03-22T18:23:58.056172Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences_df = sentences_df[sentences_df['sentence_tags'].str.len()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T18:24:00.344157Z",
     "start_time": "2020-03-22T18:24:00.327132Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T18:24:14.680361Z",
     "start_time": "2020-03-22T18:24:14.653748Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence_tags = sentences_df['sentence_tags'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T18:24:45.277531Z",
     "start_time": "2020-03-22T18:24:16.645371Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Using gensim to create a dictionary object of all the words in all extracts\n",
    "sentence_dict = gensim.corpora.Dictionary(sentence_tags)\n",
    "\n",
    "# Returning the word vector for each extract from the gensim dict of words\n",
    "sentence_vecs = [sentence_dict.doc2bow(words) for words in sentence_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T19:11:46.720223Z",
     "start_time": "2020-03-22T18:25:02.212019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the optimal number of topics\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "gensim_noun_models = []\n",
    "\n",
    "for num_topic in range(3, 10):\n",
    "    model_val = []\n",
    "    gensim_nouns = gensim.models.ldamodel.LdaModel(corpus=sentence_vecs, id2word=sentence_dict, num_topics=num_topic)\n",
    "    coh_model = CoherenceModel(model=gensim_nouns, texts=sentence_tags, dictionary=sentence_dict, coherence='c_v')\n",
    "    model_val.append(gensim_nouns)\n",
    "    model_val.append(coh_model.get_coherence())\n",
    "    model_val.append(num_topic)\n",
    "    gensim_noun_models.append(model_val)\n",
    "    print(\"Topic \" + str(num_topic) + \" Score: \" + str(coh_model.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T19:56:09.286853Z",
     "start_time": "2020-03-22T19:56:09.142239Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "coh_val = [coh for model, coh, topic in gensim_noun_models]\n",
    "\n",
    "x = range(3, 10)\n",
    "plt.plot(x, coh_val)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T19:56:13.817340Z",
     "start_time": "2020-03-22T19:56:13.764449Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Mallet LDA Model - topics\n",
    "for model in gensim_noun_models:\n",
    "    print(\"Model #{} Coherence Score: {}\".format(model[2], model[1]))\n",
    "    topics = model[0].show_topics(formatted=False)\n",
    "    for topic, word_list in topics:\n",
    "        topic_num = topic + 1\n",
    "        result_list = []\n",
    "        for word, word_prob in word_list:\n",
    "            result_list.append(word)\n",
    "        print(\"Topic {}: {}\".format(topic_num, ', '.join(result_list)))\n",
    "    print('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T19:59:38.924293Z",
     "start_time": "2020-03-22T19:59:38.818663Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE MODELS FROM ABOVE @@@@@@@@@###\n",
    "pickle.dump(gensim_noun_models, open(\"gensim_noun_models.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE MODELS FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "# gensim_noun_models = pickle.load(open(\"gensim_noun_models.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #2 LDA Mallet Model - Nouns Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T22:05:24.741006Z",
     "start_time": "2020-03-22T21:43:33.389087Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os \n",
    "\n",
    "os.environ.update({'MALLET_HOME':r'D:\\\\Softwares\\\\mallet-2.0.8'})\n",
    "mallet_path = r'D:\\\\Softwares\\\\mallet-2.0.8\\\\bin\\\\mallet'\n",
    "\n",
    "mallet_noun_models = []\n",
    "\n",
    "for num_topic in range(3, 10):\n",
    "    model_val = []\n",
    "    mallet_nouns_only = gensim.models.wrappers.LdaMallet(mallet_path, corpus=sentence_vecs, id2word=sentence_dict, num_topics=num_topic)\n",
    "    mallet_coh_model = CoherenceModel(model=mallet_nouns_only, texts=sentence_tags, dictionary=sentence_dict, coherence='c_v')\n",
    "    model_val.append(mallet_nouns_only)\n",
    "    model_val.append(mallet_coh_model.get_coherence())\n",
    "    model_val.append(num_topic)\n",
    "    mallet_noun_models.append(model_val)\n",
    "    print(\"Topic \" + str(num_topic) + \" Score: \" + str(mallet_coh_model.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T03:59:14.432451Z",
     "start_time": "2020-03-23T03:59:14.285797Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mallet_coh_val = [coh for model, coh, topic in mallet_noun_models]\n",
    "\n",
    "x = range(3, 10)\n",
    "plt.plot(x, mallet_coh_val)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T03:59:17.065877Z",
     "start_time": "2020-03-23T03:59:17.030964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mallet LDA Model - topics\n",
    "for model in mallet_noun_models:\n",
    "    print(\"Model #{} Coherence Score: {}\".format(model[2], model[1]))\n",
    "    topics = model[0].show_topics(formatted=False)\n",
    "    for topic, word_list in topics:\n",
    "        topic_num = topic + 1\n",
    "        result_list = []\n",
    "        for word, word_prob in word_list:\n",
    "            result_list.append(word)\n",
    "        print(\"Topic {}: {}\".format(topic_num, ', '.join(result_list)))\n",
    "    print('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T06:55:33.175050Z",
     "start_time": "2020-03-23T06:55:33.088279Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE MODELS FROM ABOVE @@@@@@@@@###\n",
    "pickle.dump(mallet_noun_models, open(\"mallet_noun_models.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE MODELS FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "# mallet_noun_models = pickle.load(open(\"mallet_noun_models.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #3 LDA Gensim Model - Nouns and Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T10:19:37.977861Z",
     "start_time": "2020-03-28T10:19:37.432323Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences_df = pd.DataFrame()\n",
    "sentences_df['sentence'] = sentence_list\n",
    "sentences_df['index'] = index_list\n",
    "sentences_df.dropna(inplace=True)\n",
    "\n",
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T10:19:45.358740Z",
     "start_time": "2020-03-28T10:19:43.689338Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stop_list = nltk.corpus.stopwords.words('english')\n",
    "tokenizer = nltk.tokenize.word_tokenize\n",
    "extra_stop_words = ['phone', 'iphone', 'nokia', 'samsung', 'htc', 'lg', 'galaxy', 'ca', 'motorola', 'android', 'verizon', 'i', '%', 't', 's']\n",
    "extra_stop_words += ['s4', 's5', 's6', 's7', 's3', 's8', 's9', 'm9', 'moto']\n",
    "\n",
    "def get_nouns_adj(sentence_row):\n",
    "\n",
    "    noun_list = []\n",
    "    sentence = nltk.pos_tag(tokenizer(sentence_row.lower()))\n",
    "    for w, pos in sentence: \n",
    "        if pos == 'NN' or pos == 'JJ':\n",
    "            if w not in extra_stop_words:\n",
    "                noun_list.append(w)\n",
    "    \n",
    "    return noun_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T10:38:00.159548Z",
     "start_time": "2020-03-28T10:19:47.647533Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences_df['sentence_tags'] = sentences_df['sentence'].apply(get_nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T10:38:48.165652Z",
     "start_time": "2020-03-28T10:38:48.154684Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T10:38:51.064960Z",
     "start_time": "2020-03-28T10:38:50.520415Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences_df = sentences_df[sentences_df['sentence_tags'].str.len()>0]\n",
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T10:38:53.349541Z",
     "start_time": "2020-03-28T10:38:53.331575Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence_tags = sentences_df['sentence_tags'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T10:39:12.457932Z",
     "start_time": "2020-03-28T10:39:00.727297Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Using gensim to create a dictionary object of all the words in all extracts\n",
    "sentence_dict = gensim.corpora.Dictionary(sentence_tags)\n",
    "\n",
    "# Returning the word vector for each extract from the gensim dict of words\n",
    "sentence_vecs = [sentence_dict.doc2bow(words) for words in sentence_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:35:03.005128Z",
     "start_time": "2020-03-23T09:25:49.964566Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding the optimal number of topics\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "gensim_noun_adj_models = []\n",
    "coh_val = []\n",
    "model_topics = []\n",
    "\n",
    "for num_topic in range(3, 10):\n",
    "    model_val = []\n",
    "    gensim_nouns_adj = gensim.models.ldamodel.LdaModel(corpus=sentence_vecs, id2word=sentence_dict, num_topics=num_topic)\n",
    "    coh_model = CoherenceModel(model=gensim_nouns_adj, texts=sentence_tags, dictionary=sentence_dict, coherence='c_v')\n",
    "    model_val.append(gensim_nouns_adj)\n",
    "    model_val.append(coh_model.get_coherence())\n",
    "    model_val.append(num_topic)\n",
    "    gensim_noun_adj_models.append(model_val)\n",
    "    print(\"Topic \" + str(num_topic) + \" Score: \" + str(coh_model.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:39:35.359750Z",
     "start_time": "2020-03-23T10:39:34.962808Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gensim_coh_val = [coh for model, coh, topic in gensim_noun_adj_models]\n",
    "\n",
    "x = range(3, 10)\n",
    "plt.plot(x, gensim_coh_val)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:39:47.051725Z",
     "start_time": "2020-03-23T10:39:46.985931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mallet LDA Model - topics\n",
    "for model in gensim_noun_adj_models:\n",
    "    print(\"Model #{} Coherence Score: {}\".format(model[2], model[1]))\n",
    "    topics = model[0].show_topics(formatted=False)\n",
    "    for topic, word_list in topics:\n",
    "        topic_num = topic + 1\n",
    "        result_list = []\n",
    "        for word, word_prob in word_list:\n",
    "            result_list.append(word)\n",
    "        print(\"Topic {}: {}\".format(topic_num, ', '.join(result_list)))\n",
    "    print('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T10:16:34.207559Z",
     "start_time": "2020-03-28T10:16:31.933007Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE MODELS FROM ABOVE @@@@@@@@@###\n",
    "# pickle.dump(gensim_noun_adj_models, open(\"gensim_noun_adj_models.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE MODELS FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "gensim_noun_adj_models = pickle.load(open(\"gensim_noun_adj_models.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #3 LDA Mallet Model - Nouns and Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T12:13:26.398694Z",
     "start_time": "2020-03-28T11:15:42.051844Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os \n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "os.environ.update({'MALLET_HOME':r'D:\\\\Softwares\\\\mallet-2.0.8'})\n",
    "mallet_path = r'D:\\\\Softwares\\\\mallet-2.0.8\\\\bin\\\\mallet'\n",
    "\n",
    "mallet_noun_adj_models = []\n",
    "\n",
    "for num_topic in range(3, 10):\n",
    "    model_val = []\n",
    "    mallet_noun_adj = gensim.models.wrappers.LdaMallet(mallet_path, corpus=sentence_vecs, id2word=sentence_dict, num_topics=num_topic)\n",
    "    mallet_coh_model = CoherenceModel(model=mallet_noun_adj, texts=sentence_tags, dictionary=sentence_dict, coherence='c_v')\n",
    "    model_val.append(mallet_noun_adj)\n",
    "    model_val.append(mallet_coh_model.get_coherence())\n",
    "    model_val.append(num_topic)\n",
    "    mallet_noun_adj_models.append(model_val)\n",
    "    print(\"Topic \" + str(num_topic) + \" Score: \" + str(mallet_coh_model.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T12:13:45.128384Z",
     "start_time": "2020-03-28T12:13:44.916952Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mallet_coh_val = [coh for model, coh, topic in mallet_noun_adj_models]\n",
    "\n",
    "x = range(3, 10)\n",
    "plt.plot(x, mallet_coh_val)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T12:13:49.691557Z",
     "start_time": "2020-03-28T12:13:49.647661Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mallet LDA Model - topics\n",
    "for model in mallet_noun_adj_models:\n",
    "    print(\"Model #{} Coherence Score: {}\".format(model[2], model[1]))\n",
    "    topics = model[0].show_topics(formatted=False)\n",
    "    for topic, word_list in topics:\n",
    "        topic_num = topic + 1\n",
    "        result_list = []\n",
    "        for word, word_prob in word_list:\n",
    "            result_list.append(word)\n",
    "        print(\"Topic {}: {}\".format(topic_num, ', '.join(result_list)))\n",
    "    print('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T12:13:57.875143Z",
     "start_time": "2020-03-28T12:13:57.809319Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE MODELS FROM ABOVE @@@@@@@@@###\n",
    "pickle.dump(mallet_noun_adj_models, open(\"mallet_noun_adj_models.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE MODELS FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "# mallet_noun_adj_models = pickle.load(open(\"mallet_noun_adj_models.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis (Vader & TextBlob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common methods between both SA Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE SENTENCES DF FROM ABOVE @@@@@@@@@###\n",
    "#pickle.dump(sentences_df, open(\"sentences_df.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE SENTENCES DF FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "#sentences_df = pickle.load(open(\"sentences_df.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes in the sentence column from sentence_df, returns a list of polarity scores.\n",
    "#Arg input 0 for Vader, 1 for TextBlob\n",
    "\n",
    "def sa_score(name_df,arg_num):\n",
    "    scores =[]\n",
    "    \n",
    "    if arg_num == 0:\n",
    "        try:\n",
    "            for sentence_value in name_df['sentence']:\n",
    "                score = analyser.polarity_scores(sentence_value)\n",
    "                scores.append(score)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "    else:        \n",
    "        for sentence_value in name_df['sentence']:\n",
    "            tb = TextBlob(sentence_value)\n",
    "            scores.append(tb.sentiment.polarity)\n",
    "    \n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalised(df_values):\n",
    "\n",
    "    x_2 = df_values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_2_scaled = min_max_scaler.fit_transform(x_2)\n",
    "    return pd.DataFrame(x_2_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrepancy_score(arg_list):\n",
    "    return (len(arg_list)-sum(arg_list))/len(arg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df_sa = sentences_df.copy(deep=True)\n",
    "#Drop all columns except sentence & index\n",
    "sentences_df_sa.drop(sentences_df_sa.columns.difference(['sentence','index']), 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>index</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>index scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As a diehard Samsung fan who has had every Sam...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am amazed at some of the reviews and think p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The battery life is amazing</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love the phone</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the phone is sleek and smooth and beautiful I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.8412</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025934</th>\n",
       "      <td>Came right on timr</td>\n",
       "      <td>400060</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025935</th>\n",
       "      <td>Excelente producto</td>\n",
       "      <td>400061</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025936</th>\n",
       "      <td>Older Android version, too many junky apps and...</td>\n",
       "      <td>400062</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025937</th>\n",
       "      <td>I had one die and returned it to my cell provi...</td>\n",
       "      <td>400062</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025938</th>\n",
       "      <td>Unfortunately, they just gave me another one</td>\n",
       "      <td>400062</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025939 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sentence   index    neg  \\\n",
       "0        As a diehard Samsung fan who has had every Sam...       0  0.000   \n",
       "1        I am amazed at some of the reviews and think p...       0  0.111   \n",
       "2                              The battery life is amazing       0  0.000   \n",
       "3                                           Love the phone       1  0.000   \n",
       "4        the phone is sleek and smooth and beautiful I ...       1  0.000   \n",
       "...                                                    ...     ...    ...   \n",
       "1025934                                 Came right on timr  400060  0.000   \n",
       "1025935                                 Excelente producto  400061  0.000   \n",
       "1025936  Older Android version, too many junky apps and...  400062  0.000   \n",
       "1025937  I had one die and returned it to my cell provi...  400062  0.183   \n",
       "1025938       Unfortunately, they just gave me another one  400062  0.286   \n",
       "\n",
       "           neu    pos  compound  index scores  \n",
       "0        0.813  0.187    0.6486          10.0  \n",
       "1        0.766  0.123    0.0772          10.0  \n",
       "2        0.513  0.487    0.5859          10.0  \n",
       "3        0.323  0.677    0.6369          10.0  \n",
       "4        0.653  0.347    0.8412          10.0  \n",
       "...        ...    ...       ...           ...  \n",
       "1025934  1.000  0.000    0.0000          10.0  \n",
       "1025935  1.000  0.000    0.0000          10.0  \n",
       "1025936  1.000  0.000    0.0000           4.0  \n",
       "1025937  0.599  0.219    0.0516           4.0  \n",
       "1025938  0.714  0.000   -0.3400           4.0  \n",
       "\n",
       "[1025939 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_scores = sa_score(sentences_df_sa,0)\n",
    "vader_sentencesScores = pd.concat([sentences_df_sa,pd.DataFrame(vader_scores)],axis =1, sort = False)\n",
    "vader_sentencesScores['index scores'] = index_score_list\n",
    "vader_sentencesScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_sentencesScores_sample = vader_sentencesScores.sample(n = 80, replace = False, random_state = 2)\n",
    "vader_sentencesScores_sample.to_csv(r'vader_sentencesScores_sample.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE VADER DF FROM ABOVE @@@@@@@@@###\n",
    "pickle.dump(vader_sentencesScores, open(\"VaderSentencesScores.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE VADER DF FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "#vader_sentencesScores = pickle.load(open(\"VaderSentencesScores.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "textblob_sentences = sa_score(sentences_df_sa,1)\n",
    "textblob_sentencesScores= pd.DataFrame(textblob_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025934</th>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025935</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025936</th>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025937</th>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025938</th>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025939 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         compound\n",
       "0        0.300000\n",
       "1        0.000000\n",
       "2        0.600000\n",
       "3        0.500000\n",
       "4        0.470000\n",
       "...           ...\n",
       "1025934  0.285714\n",
       "1025935  0.000000\n",
       "1025936  0.222222\n",
       "1025937  0.300000\n",
       "1025938 -0.500000\n",
       "\n",
       "[1025939 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob_sentencesScores.rename(columns={0: 'compound'}, inplace=True)\n",
    "textblob_sentencesScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE TextBlob DF FROM ABOVE @@@@@@@@@###\n",
    "pickle.dump(textblob_sentencesScores, open(\"TextBlobSentencesScores.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE TextBlob DF FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "#textblob_sentencesScores = pickle.load(open(\"TextBlobSentencesScores.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.230556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   compound\n",
       "0  0.300000\n",
       "1  0.000000\n",
       "2  0.600000\n",
       "3  0.500000\n",
       "4  0.470000\n",
       "5  0.333333\n",
       "6  0.600000\n",
       "7 -0.200000\n",
       "8  0.230556\n",
       "9  0.136364"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob_sentencesScores.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrepancy between Extract Review Score and SA Sentence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalised_scores = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_scores_title_list=[\"Vader Compound\",\"Vader Index Score\",\"TextBlob Compound\",\"TextBlob Index Score\"]\n",
    "\n",
    "df_normalised_scores[\"Vader Compound\"] = vader_sentencesScores[\"compound\"]\n",
    "df_normalised_scores[\"TextBlob Compound\"] = textblob_sentencesScores[\"compound\"]\n",
    "df_normalised_scores[\"Index Scores\"] = vader_sentencesScores[\"index scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vader Compound</th>\n",
       "      <th>TextBlob Compound</th>\n",
       "      <th>Index Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.30</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5859</td>\n",
       "      <td>0.60</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8412</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Vader Compound  TextBlob Compound  Index Scores\n",
       "0          0.6486               0.30          10.0\n",
       "1          0.0772               0.00          10.0\n",
       "2          0.5859               0.60          10.0\n",
       "3          0.6369               0.50          10.0\n",
       "4          0.8412               0.47          10.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalised_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalised_scores=normalised(df_normalised_scores.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalised_scores.rename(columns={0:'Vader Compound',1:'TextBlob Compound',2:'Index Scores'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vader Compound</th>\n",
       "      <th>TextBlob Compound</th>\n",
       "      <th>Index Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.825723</td>\n",
       "      <td>0.650</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.539321</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.794296</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.819859</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.922260</td>\n",
       "      <td>0.735</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Vader Compound  TextBlob Compound  Index Scores\n",
       "0        0.825723              0.650           1.0\n",
       "1        0.539321              0.500           1.0\n",
       "2        0.794296              0.800           1.0\n",
       "3        0.819859              0.750           1.0\n",
       "4        0.922260              0.735           1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalised_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_normalised_score = []\n",
    "tb_normalised_score = []\n",
    "comb_normalised_score = []\n",
    "comb_normalised_col = []\n",
    "\n",
    "for index, row in df_normalised_scores.iterrows():\n",
    "    vader = row['Vader Compound']\n",
    "    tb = row['TextBlob Compound']\n",
    "    comb = (vader+tb)/2\n",
    "    comb_normalised_col.append(comb)\n",
    "    index =row['Index Scores']\n",
    "    \n",
    "    vader = round(vader,2)\n",
    "    tb = round(tb,2)\n",
    "    comb = round(comb,2)\n",
    "    \n",
    "    if (vader>=(2/3) and index>=(2/3)):\n",
    "        vader_normalised_score.append(0)\n",
    "    elif((vader<(2/3) and vader>=(1/3)) and (index<(2/3) and index>=(1/3))):\n",
    "        vader_normalised_score.append(0)\n",
    "    elif(vader<(1/3) and index<(1/3)):\n",
    "        vader_normalised_score.append(0)\n",
    "    else:vader_normalised_score.append(1)\n",
    "        \n",
    "    if (tb>=(2/3) and index>=(2/3)):\n",
    "        tb_normalised_score.append(0)\n",
    "    elif((tb<(2/3) and tb>=(1/3)) and (index<(2/3) and index>=(1/3))):\n",
    "        tb_normalised_score.append(0)\n",
    "    elif(tb<(1/3) and index<(1/3)):\n",
    "        tb_normalised_score.append(0)\n",
    "    else:tb_normalised_score.append(1)\n",
    "        \n",
    "    if (comb>=(2/3) and index>=(2/3)):\n",
    "        comb_normalised_score.append(0)\n",
    "    elif((comb<(2/3) and comb>=(1/3)) and (index<(2/3) and index>=(1/3))):\n",
    "        comb_normalised_score.append(0)\n",
    "    elif(comb<(1/3) and index<(1/3)):\n",
    "        comb_normalised_score.append(0)\n",
    "    else:comb_normalised_score.append(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534153590028257\n"
     ]
    }
   ],
   "source": [
    "#Vader Accuracy \n",
    "vader_accuracy = discrepancy_score(vader_normalised_score)\n",
    "print(vader_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45430186395097566\n"
     ]
    }
   ],
   "source": [
    "#Textblob Accuracy \n",
    "tb_accuracy = discrepancy_score(tb_normalised_score)\n",
    "print(tb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4877902097493126\n"
     ]
    }
   ],
   "source": [
    "#Comb Accuracy \n",
    "comb_accuracy = discrepancy_score(comb_normalised_score)\n",
    "print(comb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalised_scores.insert(loc=2, column='Mean Compound', value=comb_normalised_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalised_scores.insert(loc=4, column='Combined normalised score', value=comb_normalised_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalised_scores[\"sentence\"]=vader_sentencesScores[\"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vader Compound</th>\n",
       "      <th>TextBlob Compound</th>\n",
       "      <th>Mean Compound</th>\n",
       "      <th>Index Scores</th>\n",
       "      <th>Combined normalised score</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.825723</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.737862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>As a diehard Samsung fan who has had every Sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.539321</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.519661</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>I am amazed at some of the reviews and think p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.794296</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.797148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>The battery life is amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.819859</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.784929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Love the phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.922260</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.828630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>the phone is sleek and smooth and beautiful I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.362538</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.431269</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>I do not like this phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.500627</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500313</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>I had it in my pocket with something else and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.500627</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500313</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced it and it has another crack in it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.500627</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500313</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>They need to do something different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.932284</td>\n",
       "      <td>0.677273</td>\n",
       "      <td>0.804778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>I love my new phone it really have lot great n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Vader Compound  TextBlob Compound  Mean Compound  Index Scores  \\\n",
       "0         0.825723           0.650000       0.737862      1.000000   \n",
       "1         0.539321           0.500000       0.519661      1.000000   \n",
       "2         0.794296           0.800000       0.797148      1.000000   \n",
       "3         0.819859           0.750000       0.784929      1.000000   \n",
       "4         0.922260           0.735000       0.828630      1.000000   \n",
       "..             ...                ...            ...           ...   \n",
       "95        0.362538           0.500000       0.431269      0.111111   \n",
       "96        0.500627           0.500000       0.500313      0.111111   \n",
       "97        0.500627           0.500000       0.500313      0.111111   \n",
       "98        0.500627           0.500000       0.500313      0.111111   \n",
       "99        0.932284           0.677273       0.804778      1.000000   \n",
       "\n",
       "    Combined normalised score  \\\n",
       "0                           0   \n",
       "1                           1   \n",
       "2                           0   \n",
       "3                           0   \n",
       "4                           0   \n",
       "..                        ...   \n",
       "95                          1   \n",
       "96                          1   \n",
       "97                          1   \n",
       "98                          1   \n",
       "99                          0   \n",
       "\n",
       "                                             sentence  \n",
       "0   As a diehard Samsung fan who has had every Sam...  \n",
       "1   I am amazed at some of the reviews and think p...  \n",
       "2                         The battery life is amazing  \n",
       "3                                      Love the phone  \n",
       "4   the phone is sleek and smooth and beautiful I ...  \n",
       "..                                                ...  \n",
       "95                           I do not like this phone  \n",
       "96  I had it in my pocket with something else and ...  \n",
       "97         Replaced it and it has another crack in it  \n",
       "98                They need to do something different  \n",
       "99  I love my new phone it really have lot great n...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalised_scores.head(100)\n",
    "#Combined normalised score of 0 indicates an accurate sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_normalised_scores.to_csv(r'df_normalised_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_normalised_scores=pd.read_csv('df_normalised_scores.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE normalised DF FROM ABOVE @@@@@@@@@###\n",
    "pickle.dump(df_normalised_scores, open(\"df_normalised_scores.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE normalised DF FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "#df_normalised_scores = pickle.load(open(\"df_normalised_scores.pkl\", \"rb\"))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_sample = df_normalised_scores.sample(n = 80, replace = False, random_state = 42)\n",
    "sa_sample.to_csv(r'sa_sample.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vader Compound</th>\n",
       "      <th>TextBlob Compound</th>\n",
       "      <th>Mean Compound</th>\n",
       "      <th>Index Scores</th>\n",
       "      <th>Combined normalised score</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.825723</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.737862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>As a diehard Samsung fan who has had every Sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.539321</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.519661</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>I am amazed at some of the reviews and think p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.794296</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.797148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>The battery life is amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.819859</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.784929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Love the phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.922260</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.828630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>the phone is sleek and smooth and beautiful I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025934</th>\n",
       "      <td>0.500627</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.571742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Came right on timr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025935</th>\n",
       "      <td>0.500627</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500313</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>Excelente producto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025936</th>\n",
       "      <td>0.500627</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.555869</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>Older Android version, too many junky apps and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025937</th>\n",
       "      <td>0.526490</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.588245</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>I had one die and returned it to my cell provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025938</th>\n",
       "      <td>0.330209</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.290105</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, they just gave me another one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1025939 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Vader Compound  TextBlob Compound  Mean Compound  Index Scores  \\\n",
       "0              0.825723           0.650000       0.737862      1.000000   \n",
       "1              0.539321           0.500000       0.519661      1.000000   \n",
       "2              0.794296           0.800000       0.797148      1.000000   \n",
       "3              0.819859           0.750000       0.784929      1.000000   \n",
       "4              0.922260           0.735000       0.828630      1.000000   \n",
       "...                 ...                ...            ...           ...   \n",
       "1025934        0.500627           0.642857       0.571742      1.000000   \n",
       "1025935        0.500627           0.500000       0.500313      1.000000   \n",
       "1025936        0.500627           0.611111       0.555869      0.333333   \n",
       "1025937        0.526490           0.650000       0.588245      0.333333   \n",
       "1025938        0.330209           0.250000       0.290105      0.333333   \n",
       "\n",
       "         Combined normalised score  \\\n",
       "0                                0   \n",
       "1                                1   \n",
       "2                                0   \n",
       "3                                0   \n",
       "4                                0   \n",
       "...                            ...   \n",
       "1025934                          1   \n",
       "1025935                          1   \n",
       "1025936                          0   \n",
       "1025937                          0   \n",
       "1025938                          1   \n",
       "\n",
       "                                                  sentence  \n",
       "0        As a diehard Samsung fan who has had every Sam...  \n",
       "1        I am amazed at some of the reviews and think p...  \n",
       "2                              The battery life is amazing  \n",
       "3                                           Love the phone  \n",
       "4        the phone is sleek and smooth and beautiful I ...  \n",
       "...                                                    ...  \n",
       "1025934                                 Came right on timr  \n",
       "1025935                                 Excelente producto  \n",
       "1025936  Older Android version, too many junky apps and...  \n",
       "1025937  I had one die and returned it to my cell provi...  \n",
       "1025938       Unfortunately, they just gave me another one  \n",
       "\n",
       "[1025939 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normalised_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop all Neutrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vader Compound</th>\n",
       "      <th>TextBlob Compound</th>\n",
       "      <th>Mean Compound</th>\n",
       "      <th>Index Scores</th>\n",
       "      <th>Combined normalised score</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.825723</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.737862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>As a diehard Samsung fan who has had every Sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.539321</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.519661</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>I am amazed at some of the reviews and think p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.794296</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.797148</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>The battery life is amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.819859</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.784929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Love the phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.922260</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.828630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>the phone is sleek and smooth and beautiful I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Vader Compound  TextBlob Compound  Mean Compound  Index Scores  \\\n",
       "0        0.825723              0.650       0.737862           1.0   \n",
       "1        0.539321              0.500       0.519661           1.0   \n",
       "2        0.794296              0.800       0.797148           1.0   \n",
       "3        0.819859              0.750       0.784929           1.0   \n",
       "4        0.922260              0.735       0.828630           1.0   \n",
       "\n",
       "   Combined normalised score  \\\n",
       "0                          0   \n",
       "1                          1   \n",
       "2                          0   \n",
       "3                          0   \n",
       "4                          0   \n",
       "\n",
       "                                            sentence  \n",
       "0  As a diehard Samsung fan who has had every Sam...  \n",
       "1  I am amazed at some of the reviews and think p...  \n",
       "2                        The battery life is amazing  \n",
       "3                                     Love the phone  \n",
       "4  the phone is sleek and smooth and beautiful I ...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_no_neutrals = df_normalised_scores.copy(deep = True)\n",
    "vader_no_neutrals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_no_neutrals.drop([\"TextBlob Compound\",\"Mean Compound\",\"Index Scores\",\"Combined normalised score\"],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           True\n",
       "1          False\n",
       "2           True\n",
       "3           True\n",
       "4           True\n",
       "           ...  \n",
       "1025934    False\n",
       "1025935    False\n",
       "1025936    False\n",
       "1025937    False\n",
       "1025938    False\n",
       "Name: Vader Compound, Length: 1025939, dtype: bool"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(vader_no_neutrals['Vader Compound'] > 2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vader Compound</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Vader Compound, sentence]\n",
       "Index: []"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_no_neutrals= vader_no_neutrals[(vader_no_neutrals['Vader Compound'] >= 2/3) & (1/3 >= vader_no_neutrals['Vader Compound'])]\n",
    "\n",
    "vader_no_neutrals.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_no_neutrals = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_no_neutrals = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVERYTHING BELOW ARE VERSION 1 CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T12:44:20.452391Z",
     "start_time": "2020-03-22T12:44:20.443412Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing of extracts into words\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "def clean_extract(extract_data):\n",
    "    stop_list = nltk.corpus.stopwords.words('english')\n",
    "    stop_list += ['phone', 'iphone', 'nokia', 'samsung', 'htc', 'lg', 'galaxy', 'ca', 'motorola', 'android', 'verizon']\n",
    "    tokenizer = nltk.tokenize.word_tokenize\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "    extract_list  = [tokenizer(extract) for extract in extract_data]\n",
    "    extract_list = [[w.lower() for w in extract] for extract in extract_list]\n",
    "    extract_list = [[w for w in extract if re.search('^[a-z]+$',w)] for extract in extract_list]\n",
    "    extract_list = [[w for w in extract if w not in stop_list] for extract in extract_list]\n",
    "#     extract_list = [[stemmer.stem(w) for w in extract] for extract in extract_list]\n",
    "    return extract_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:22:15.970356Z",
     "start_time": "2020-02-27T18:18:51.560253Z"
    }
   },
   "outputs": [],
   "source": [
    "extract_list = cleaned_df['extract'].values.tolist()\n",
    "extract_words = clean_extract(extract_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:22:34.550218Z",
     "start_time": "2020-02-27T18:22:15.972325Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Using gensim to create a dictionary object of all the words in all extracts\n",
    "extract_dict = gensim.corpora.Dictionary(extract_words)\n",
    "\n",
    "# Returning the word vector for each extract from the gensim dict of words\n",
    "extract_vecs = [extract_dict.doc2bow(extract) for extract in extract_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:04:44.273452Z",
     "start_time": "2020-02-27T18:23:48.353290Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the optimal number of topics\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "model_list = []\n",
    "coh_val = []\n",
    "model_topics = []\n",
    "\n",
    "for num_topic in range(3, 10):\n",
    "    extract_lda_gensim = gensim.models.ldamodel.LdaModel(corpus=extract_vecs, id2word=extract_dict, num_topics=num_topic)\n",
    "    coh_model = CoherenceModel(model=extract_lda_gensim, texts=extract_words, dictionary=extract_dict, coherence='c_v')\n",
    "    model_topics.append(num_topic)\n",
    "    model_list.append(extract_lda_gensim)\n",
    "    coh_val.append(coh_model.get_coherence())\n",
    "    print(\"Topic \" + str(num_topic) + \" Score: \" + str(coh_model.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T06:37:32.539326Z",
     "start_time": "2020-02-28T06:37:32.394708Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(3, 10)\n",
    "plt.plot(x, coh_val)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:04:47.231156Z",
     "start_time": "2020-02-27T20:04:47.106498Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gensim LDA Model - topics\n",
    "val = 0\n",
    "model_num = 3\n",
    "for model in model_list:\n",
    "    print(\"Model #{} Coherence Score: {}\".format(model_num, coh_val[val]))\n",
    "    topics = model.show_topics(formatted=False)\n",
    "    for topic, word_list in topics:\n",
    "        topic_num = topic + 1\n",
    "        result_list = []\n",
    "        for word, word_prob in word_list:\n",
    "            result_list.append(word)\n",
    "        print(\"Topic {}: {}\".format(topic_num, ', '.join(result_list)))\n",
    "    model_num += 1\n",
    "    val += 1\n",
    "    print('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T20:04:47.411386Z",
     "start_time": "2020-02-27T20:04:47.236140Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE GENSIM MODELS FROM ABOVE @@@@@@@@@###\n",
    "pickle.dump(model_list, open(\"gensim_models.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE GENSIM MODELS FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "# gensim_models = pickle.load(open(\"gensim_models.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mallet LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T22:06:39.757935Z",
     "start_time": "2020-02-27T20:04:47.415334Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os \n",
    "\n",
    "os.environ.update({'MALLET_HOME':r'D:\\\\Softwares\\\\mallet-2.0.8'})\n",
    "mallet_path = r'D:\\\\Softwares\\\\mallet-2.0.8\\\\bin\\\\mallet'\n",
    "\n",
    "model_list_mallet = []\n",
    "coh_val_mallet = []\n",
    "\n",
    "for num_topic in range(3, 10):\n",
    "    extract_lda_mallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=extract_vecs, id2word=extract_dict, num_topics=num_topic)\n",
    "    coh_model_mallet = CoherenceModel(model=extract_lda_mallet, texts=extract_words, dictionary=extract_dict, coherence='c_v')\n",
    "    model_list_mallet.append(extract_lda_mallet)\n",
    "    coh_val_mallet.append(coh_model_mallet.get_coherence())\n",
    "    print(\"Topic \" + str(num_topic) + \" Score: \" + str(coh_model_mallet.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T22:06:40.177889Z",
     "start_time": "2020-02-27T22:06:39.762920Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(3, 10)\n",
    "plt.plot(x, coh_val_mallet)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T06:37:10.440676Z",
     "start_time": "2020-02-28T06:37:10.382831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mallet LDA Model - topics\n",
    "val = 0\n",
    "mallet_model_num = 3\n",
    "for model in model_list_mallet:\n",
    "    print(\"Model #{} Coherence Score: {}\".format(mallet_model_num, coh_val_mallet[val]))\n",
    "    topics = model.show_topics(formatted=False)\n",
    "    for topic, word_list in topics:\n",
    "        topic_num = topic + 1\n",
    "        result_list = []\n",
    "        for word, word_prob in word_list:\n",
    "            result_list.append(word)\n",
    "        print(\"Topic {}: {}\".format(topic_num, ', '.join(result_list)))\n",
    "    mallet_model_num += 1\n",
    "    val += 1\n",
    "    print('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T22:06:40.452944Z",
     "start_time": "2020-02-27T22:06:40.273941Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE MALLET MODELS FROM ABOVE @@@@@@@@@###\n",
    "pickle.dump(model_list_mallet, open(\"mallet_models.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE GENSIM MODELS FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "# mallet_models = pickle.load(open(\"mallet_models.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T06:42:26.816859Z",
     "start_time": "2020-02-28T06:42:26.808881Z"
    }
   },
   "outputs": [],
   "source": [
    "## Another Gensim run with more words taken out from the stop list \n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "def clean_extract2(extract_data):\n",
    "    stop_list = nltk.corpus.stopwords.words('english')\n",
    "    stop_list += ['phone', 'iphone', 'nokia', 'samsung', 'htc', 'lg', 'galaxy', 'ca', '']\n",
    "    tokenizer = nltk.tokenize.word_tokenize\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "    extract_list  = [tokenizer(extract) for extract in extract_data]\n",
    "    extract_list = [[w.lower() for w in extract] for extract in extract_list]\n",
    "    extract_list = [[w for w in extract if re.search('^[a-z]+$',w)] for extract in extract_list]\n",
    "    extract_list = [[w for w in extract if w not in stop_list] for extract in extract_list]\n",
    "#     extract_list = [[stemmer.stem(w) for w in extract] for extract in extract_list]\n",
    "    return extract_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T06:45:52.637625Z",
     "start_time": "2020-02-28T06:42:54.823674Z"
    }
   },
   "outputs": [],
   "source": [
    "extract_list2 = cleaned_df['extract'].values.tolist()\n",
    "extract_words2 = clean_extract2(extract_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T06:46:09.410341Z",
     "start_time": "2020-02-28T06:45:52.638623Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Using gensim to create a dictionary object of all the words in all extracts\n",
    "extract_dict2 = gensim.corpora.Dictionary(extract_words2)\n",
    "\n",
    "# Returning the word vector for each extract from the gensim dict of words\n",
    "extract_vecs2 = [extract_dict2.doc2bow(extract) for extract in extract_words2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T07:24:37.788933Z",
     "start_time": "2020-02-28T06:46:09.411307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the optimal number of topics\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "model_list2 = []\n",
    "coh_val2 = []\n",
    "model_topics2 = []\n",
    "\n",
    "for num_topic in range(3, 10):\n",
    "    extract_lda_gensim2 = gensim.models.ldamodel.LdaModel(corpus=extract_vecs2, id2word=extract_dict2, num_topics=num_topic)\n",
    "    coh_model2 = CoherenceModel(model=extract_lda_gensim2, texts=extract_words2, dictionary=extract_dict2, coherence='c_v')\n",
    "    model_topics2.append(num_topic)\n",
    "    model_list2.append(extract_lda_gensim2)\n",
    "    coh_val2.append(coh_model2.get_coherence())\n",
    "    print(\"Topic \" + str(num_topic) + \" Score: \" + str(coh_model2.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T07:59:51.431541Z",
     "start_time": "2020-02-28T07:59:51.275958Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(3, 10)\n",
    "plt.plot(x, coh_val2)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:02:06.178800Z",
     "start_time": "2020-02-28T08:02:06.137910Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2nd Gensim LDA Model - topics\n",
    "val2 = 0\n",
    "model_num2 = 3\n",
    "for model in model_list2:\n",
    "    print(\"Model #{} Coherence Score: {}\".format(model_num2, coh_val2[val2]))\n",
    "    topics = model.show_topics(formatted=False)\n",
    "    for topic, word_list in topics:\n",
    "        topic_num = topic + 1\n",
    "        result_list2 = []\n",
    "        for word, word_prob in word_list:\n",
    "            result_list2.append(word)\n",
    "        print(\"Topic {}: {}\".format(topic_num, ', '.join(result_list2)))\n",
    "    model_num2 += 1\n",
    "    val2 += 1\n",
    "    print('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:03:12.898791Z",
     "start_time": "2020-02-28T08:03:12.815659Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE MALLET MODELS FROM ABOVE @@@@@@@@@###\n",
    "pickle.dump(model_list2, open(\"gensim_models2.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE GENSIM MODELS FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "# mallet_models = pickle.load(open(\"mallet_models.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:54:29.898687Z",
     "start_time": "2020-02-28T08:04:27.954290Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2nd Mallet LDA Model\n",
    "import gensim\n",
    "import os \n",
    "\n",
    "os.environ.update({'MALLET_HOME':r'D:\\\\Softwares\\\\mallet-2.0.8'})\n",
    "mallet_path = r'D:\\\\Softwares\\\\mallet-2.0.8\\\\bin\\\\mallet'\n",
    "\n",
    "model_list_mallet2 = []\n",
    "coh_val_mallet2 = []\n",
    "\n",
    "for num_topic in range(3, 10):\n",
    "    extract_lda_mallet2 = gensim.models.wrappers.LdaMallet(mallet_path, corpus=extract_vecs2, id2word=extract_dict2, num_topics=num_topic)\n",
    "    coh_model_mallet2 = CoherenceModel(model=extract_lda_mallet2, texts=extract_words2, dictionary=extract_dict2, coherence='c_v')\n",
    "    model_list_mallet2.append(extract_lda_mallet2)\n",
    "    coh_val_mallet2.append(coh_model_mallet2.get_coherence())\n",
    "    print(\"Topic \" + str(num_topic) + \" Score: \" + str(coh_model_mallet2.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:54:30.053319Z",
     "start_time": "2020-02-28T08:54:29.901682Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(3, 10)\n",
    "plt.plot(x, coh_val_mallet2)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:54:30.098200Z",
     "start_time": "2020-02-28T08:54:30.055313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mallet LDA Model - topics\n",
    "val = 0\n",
    "mallet_model_num = 3\n",
    "for model in model_list_mallet2:\n",
    "    print(\"Model #{} Coherence Score: {}\".format(mallet_model_num, coh_val_mallet2[val]))\n",
    "    topics = model.show_topics(formatted=False)\n",
    "    for topic, word_list in topics:\n",
    "        topic_num = topic + 1\n",
    "        result_list = []\n",
    "        for word, word_prob in word_list:\n",
    "            result_list.append(word)\n",
    "        print(\"Topic {}: {}\".format(topic_num, ', '.join(result_list)))\n",
    "    mallet_model_num += 1\n",
    "    val += 1\n",
    "    print('----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T08:54:30.170102Z",
     "start_time": "2020-02-28T08:54:30.099232Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***SAVE*** THE MALLET MODELS FROM ABOVE @@@@@@@@@###\n",
    "pickle.dump(model_list_mallet2, open(\"mallet_models2.pkl\", \"wb\"))\n",
    "\n",
    "###@@@@@@@@@ THIS IS TO ***OPEN*** THE GENSIM MODELS FROM THE STORED PICKLE FILE @@@@@@@@@###\n",
    "### CHECKPOINT - can just load the pickle file and start running your analysis\n",
    "# mallet_models = pickle.load(open(\"mallet_models.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Another Gensim run with more words taken out from the stop list \n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "\n",
    "def clean_extract2(extract_data):\n",
    "    stop_list = nltk.corpus.stopwords.words('english')\n",
    "    stop_list += ['phone', 'iphone', 'nokia', 'samsung', 'htc', 'lg', 'galaxy', 'ca', '']\n",
    "    tokenizer = nltk.tokenize.word_tokenize\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "    extract_list  = [tokenizer(extract) for extract in extract_data]\n",
    "    extract_list = [[w.lower() for w in extract] for extract in extract_list]\n",
    "    extract_list = [[w for w in extract if re.search('^[a-z]+$',w)] for extract in extract_list]\n",
    "    extract_list = [[w for w in extract if w not in stop_list] for extract in extract_list]\n",
    "#     extract_list = [[stemmer.stem(w) for w in extract] for extract in extract_list]\n",
    "    return extract_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T13:53:25.610183Z",
     "start_time": "2020-02-28T13:53:25.588019Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "new_query = 'Good phone screen good battery life'\n",
    "tokenizer = nltk.tokenize.word_tokenize\n",
    "cleaned_query = tokenizer(new_query)\n",
    "cleaned_query = [w.lower() for w in cleaned_query]\n",
    "cleaned_query = [w for w in cleaned_query if re.search('^[a-z]+$',w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T13:55:16.679144Z",
     "start_time": "2020-02-28T13:55:16.669792Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Returning the word vector for each extract from the gensim dict of words\n",
    "query_vecs = extract_dict2.doc2bow(cleaned_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T14:07:49.950126Z",
     "start_time": "2020-02-28T14:06:13.143996Z"
    }
   },
   "outputs": [],
   "source": [
    "output = list(model_list_mallet2[4][query_vecs])\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
